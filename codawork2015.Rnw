\documentclass[10pt]{beamer}

\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{array}
\usepackage{amsmath, amssymb, bbm}
\usepackage{verbatim}
\usepackage{relsize}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{ragged2e}
%\usetheme{Warsaw}
%\usepackage{dsfont}
%\usecolortheme{lily}

\definecolor{obs}{RGB}{53,106,160}
\definecolor{post}{RGB}{0,110,46}
\definecolor{class}{RGB}{160,110,46}
\definecolor{idea}{RGB}{162,162,162}

\definecolor{gg1}{RGB}{248,118,109}
\definecolor{gg2}{RGB}{183,159,0}
\definecolor{gg3}{RGB}{0,186,56}
\definecolor{gg4}{RGB}{0,191,196}
\definecolor{gg5}{RGB}{97,156,255}
\definecolor{gg6}{RGB}{245,100,227}

\newcommand{\obs}[1]{{\color{obs}#1}}
\newcommand{\post}[1]{{\color{post}#1}}
\newcommand{\class}[1]{{\color{class}#1}}
\newcommand{\idea}[1]{{\uncover<2>{\color{idea}#1}}}
\newcommand{\tidea}[2]{{\uncover<#1>{\color{idea}#2}}}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\blue}[1]{{\color{blue}#1}}

\newcommand{\gga}[1]{{\color{gg1}#1}}
\newcommand{\ggb}[1]{{\color{gg2}#1}}
\newcommand{\ggc}[1]{{\color{gg3}#1}}
\newcommand{\ggd}[1]{{\color{gg4}#1}}
\newcommand{\gge}[1]{{\color{gg5}#1}}
\newcommand{\ggf}[1]{{\color{gg6}#1}}

\title{A compositional approach for merging finite mixture components}
\subtitle{CoDaWork 2015, l'Escala}
\author{\emph{Marc~Comas-Cufí} \\ \and Josep~Antoni~Martín-Fernández \\\and Glòria~Mateu-Figueras}
\institute{Universitat de Girona}
\date{June 3rd, 2015}

\begin{document}


\begin{frame}
\titlepage
\end{frame}

<<echo=FALSE, include=FALSE>>=
knitr::opts_chunk$set(comment=NA, echo=FALSE)
library(ggplot2)
library(mclust)
library(dplyr)
library(mixpack)
library(grid)
library(gridBase)
options(width=200)
knitr::opts_chunk$set(comment = " ", echo = FALSE, warning = FALSE)
rnormmix = function(n, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1)){
  df = apply(cbind(mean, sd), 1, function(pars) rnorm(n, mean=pars[1], sd=pars[2]))
  z = sapply(sample(1:3, size = n, replace = TRUE, prob = pi), function(i) 1:3 == i)
  df[t(z)]
}
dnormmix = function(x, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1)){
  df = apply(cbind(pi, mean, sd), 1, function(pars) pars[1] * dnorm(x, mean=pars[2], sd=pars[3]))
  apply(df, 1, sum)
}
cnormmix = function(x, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1),
                    class = 1:length(pi)){
  df = apply(cbind(pi, mean, sd), 1, function(pars) pars[1] * dnorm(x, mean=pars[2], sd=pars[3]))
  as.factor(class[apply(df, 1, which.max)])
}
get_sample = function(seed = 2){
  set.seed(seed)
  Pi = c(2/9, 4/9, 3/9)
  Mean = c(-2, 3.5, 5)
  Sd = c(0.65,1.2,0.8)
  df = data.frame('x' = rnormmix(n = 100,  pi = Pi, mean = Mean, sd = Sd))
  df$f = dnormmix(df$x, pi = Pi, mean = Mean, sd = Sd)
  df$class = cnormmix(df$x, pi = Pi, mean = Mean, sd = Sd)
  df$class2 = cnormmix(df$x, pi = Pi, mean = Mean, sd = Sd, class=c(1,2,2))
  df$f1 = Pi[1] * dnorm(df$x, mean = Mean[1], sd = Sd[1]) / df$f
  df$f2 = Pi[2] * dnorm(df$x, mean = Mean[2], sd = Sd[2]) / df$f
  df$f3 = Pi[3] * dnorm(df$x, mean = Mean[3], sd = Sd[3]) / df$f
  df.dens = data.frame('x' = seq(-5, 10, 0.2))
  df.dens$f = dnormmix(df.dens$x, pi = Pi, mean = Mean, sd = Sd)
  df.dens$f1 = Pi[1] * dnorm(df.dens$x, mean = Mean[1], sd = Sd[1])
  df.dens$f2 = Pi[2] * dnorm(df.dens$x, mean = Mean[2], sd = Sd[2])
  df.dens$f3 = Pi[3] * dnorm(df.dens$x, mean = Mean[3], sd = Sd[3])
  list('sample' = df, 'density' = df.dens)
}
@

\section{Introducing the purpose of merging components}

\begin{frame}
\frametitle{How many groups do you see here?}
\begin{itemize}
\item Consider the following sample $X = \{x_1,\dots,x_{100} \}$:
\end{itemize}

\begin{columns}[T]
\begin{column}{0.6\textwidth}
\only<1>{
<<fig.width=4, fig.height=3>>=
v_xlim = c(-5, 8)
X = get_sample()
df = X$sample
df.dens = X$density

(p1 <- ggplot() + 
  geom_histogram(data=df, aes(x=x, y = ..density..), binwidth=0.5, col='black', fill='white') +
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.01), alpha=1) +
  theme_bw() + xlim(v_xlim) + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(),  panel.grid=element_blank()) +
  ylab(NULL) + xlab(NULL))
@
}
\only<2>{
<<fig.width=4, fig.height=3>>=
df$km = ifelse(df$x < 0, '1', '2')
ggplot() + 
  geom_histogram(data=df, aes(x=x, fill=km), binwidth=0.5, alpha=0.15, col='black') +
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.5, col=km), alpha=1) +
  theme_bw() + xlim(v_xlim) + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(),  panel.grid=element_blank()) +
  ylab(NULL) + xlab(NULL)  + theme(legend.position="none")
@
}
\end{column}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{Common approach in model based clustering}
\begin{itemize}
\item Number of components $K$: BIC criteria the most common.%
\only<1>{ \[ f(x) = \pi_1 f_1(x;\theta_1) + \dots + \pi_K f_K(x;\theta_K). \] }%
\only<2>{ \[ f(x) = \pi_1 f_1(x;\theta_1) + \pi_2 f_2(x;\theta_2) + \pi_3 f_3(x;\theta_3). \] }%
\only<3->{ \[ f(x) = {\color{red}\pi_1 f_1(x;\theta_1)} + {\color{green}\pi_2 f_2(x;\theta_2)} + {\color{blue}\pi_3 f_3(x;\theta_3)}. \] }%
\item<4-> Observation are assigned to the component most likely belong to.
\end{itemize}

\begin{columns}[T]
\begin{column}{0.6\textwidth}
\only<1-2>{
<<fig.width=4, fig.height=3>>=
p1
@
}
\only<3>{
<<fig.width=4, fig.height=3>>=
(p3 <- p1 +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2), size = 1, col = 'green', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f3), size = 1, col = 'blue', alpha=0.6)) + 
  theme(legend.position="none", panel.grid=element_blank())
@
}
\only<4>{
<<fig.width=4, fig.height=3>>=
(p1c <- ggplot() + 
  geom_histogram(data=df, aes(x=x, y = ..density..), binwidth=0.5, col='black', fill='white', alpha=0.6) +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2), size = 1, col = 'green', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f3), size = 1, col = 'blue', alpha=0.6) + 
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.01, col=class), alpha=1) + 
  theme_bw() +  theme(legend.position="none", panel.grid=element_blank()) +xlim(v_xlim) + 
   theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) + ylab(NULL) + xlab(NULL) +  
   scale_color_manual(values = c("red", "green", "blue")))
@
}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[t]
\frametitle{Common approach in model based clustering}

\begin{columns}[T]
\begin{column}{0.33\textwidth}
<<fig.width=4, fig.height=3>>=
p1c
@
\end{column}
\begin{column}{0.33\textwidth}
\uncover<4->{%
\only<1-4>{
<<fig.width=4, fig.height=3>>=
(p32 <- p1 +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2+f3), size = 1, col = 'blue', alpha=0.6))

@
}
\only<5>{
<<fig.width=4, fig.height=3>>=
(p12c <- ggplot() + 
  geom_histogram(data=df, aes(x=x, y = ..density..), binwidth=0.5, col='black', fill='white', alpha=0.6) +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2+f3), size = 1, col = 'blue', alpha=0.6) + 
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.01, col=class), alpha=1) + 
  theme_bw() + theme(legend.position="none", panel.grid=element_blank()) +xlim(v_xlim) + 
   theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) + ylab(NULL) + xlab(NULL) +  
   scale_color_manual(values = c("red", "blue", "blue")))
@
}
}
\end{column}
\end{columns}
\begin{itemize}
\item Given the finite mixture
\only<1-3>{\[ f(x) = {\color{red}\pi_1 f_1(x;\theta_1)} + {\color{green}\pi_2 f_2(x;\theta_2)} + {\color{blue}\pi_3 f_3(x;\theta_3)},\]}
\only<4->{\[ f(x) = {\color{red}\pi_1 f_1(x;\theta_1)} + {\color{blue} (\pi_2+\pi_3)\left\{ \frac{\pi_2}{\pi_2+\pi_3} f_2(x;\theta_2) + \frac{\pi_3}{\pi_2+\pi_3} f_3(x;\theta_3) \right\}},\]}
we assign an observation $x_i$ to the higher component
\only<1>{ \[ \left({\color{red}\frac{\pi_1 f_1(x_i;\theta_1)}{\sum_{\ell=1}^3 \pi_\ell f_\ell(x_i;\theta_\ell)}}, {\color{green}\frac{\pi_2 f_2(x_i;\theta_2)}{\sum_{\ell=1}^3 \pi_\ell f_\ell(x_i;\theta_\ell)}}, {\color{blue}\frac{\pi_3 f_3(x_i;\theta_3)}{\sum_{\ell=1}^3 \pi_\ell f_\ell(x_i;\theta_\ell)}} \right) \] }
\only<2-3>{ \[ \left({\color{red}\pi_1 f_1(x_i;\theta_1)}, {\color{green}\pi_2 f_2(x_i;\theta_2)}, {\color{blue}\pi_3 f_3(x_i;\theta_3)} \right) \] }
\only<4>{ \[ \left({\color{red}\pi_1 f_1(x_i;\theta_1)}, {\color{blue}\pi_2 f_2(x_i;\theta_2) + \pi_3 f_3(x_i;\theta_3)} \right) \] }
\item<3-> A different approach is to consider a \alert{mixture of mixtures}
\end{itemize}

\end{frame}

<<include=FALSE>>=
set.seed(3)
ms = c(runif(3, min = -2 , max= -1), runif(3, min = 0 , max= 1), runif(3, min = 2 , max= 3))
x = Reduce('c', lapply(ms, function(m) rnorm(1000, m, 0.1)))
mc = Mclust(x, G = 2:10)

df.d = data.frame(
  x = x,
  class = mc$classification)

hp = get_hierarchical_partition(mc$z, lambda = function(v_tau, a, b) if(which.max(v_tau) == b) 1 else 0, omega = function(v_tau, a) v_tau[a])
@

<<include=FALSE>>=
draw_partition = function(LVL){
  p = ggplot() + 
    geom_histogram(data=df.d, aes(x=x, y = ..density..), binwidth=0.1, col='black', fill='white', alpha=0.6)
  
  for(i in hp[[LVL]]){
    df.d.dens = data.frame(x = seq(-3, 4, length=1000)) 
    func = function(x) Reduce(`+`, lapply(i, function(i) mc$parameters$pro[i] * dnorm(x, mean = mc$parameters$mean[i], sd = sqrt(mc$parameters$variance$sigmasq) )))
    p = p + geom_line(data=df.d.dens %>% mutate(f = func(x)), aes(x=x, y=f), size = 1, col = rainbow(8)[1+(3+i[[1]])%%8], alpha=0.99)
  }
  
  p + theme_bw() +  theme(legend.position="none") + 
    theme(axis.ticks = element_blank(), 
          axis.text = element_blank(),
          panel.grid=element_blank(),
          panel.border = element_blank()) + ylab(NULL) + ylim(0,1) + xlab(NULL)
}
@

<<include=FALSE>>=
library(dendextend)

set_diff = lapply(8:2, function(i) unlist(setdiff(hp[[i-1]], hp[[i]])))
cummulative = lapply(1:7, function(till, set_diff){
  if(till>1)
    Reduce('union', set_diff[1:(till-1)])
  else
    integer(0)
}, set_diff)
set_diff2 = mapply(intersect, set_diff, cummulative)

leafs = mapply(setdiff, set_diff, set_diff2)




a = list()
a$merge = do.call('rbind', lapply(1:7, function(i){
  if(length(leafs[[i]]) == 2){
    return(-leafs[[i]])
  }
  if(length(leafs[[i]]) == 1){
    i1 = max(which(sapply(set_diff[1:(i-1)], 
                          function(s) 
                            length(setdiff(setdiff(set_diff[[i]], leafs[[i]]), s)) == 0)))
    return(c(-leafs[[i]], i1))
  }
  if(length(leafs[[i]]) == 0){
    i1 = max(which(sapply(set_diff[1:(i-1)], 
                          function(s) 
                            length(setdiff(s, setdiff(set_diff[[i]], leafs[[i]]))) == 0)))
    i2 = max(which(sapply(set_diff[1:(i-1)], 
                          function(s) 
                            length(setdiff(s, setdiff(setdiff(set_diff[[i]], set_diff[[i1]]), leafs[[i]]))) == 0)))
    return(c(i1, i2))
  }
}))
a$height <- 1:nrow(a$merge)
a$order <- hp[[1]][[1]]
a$labels <- rep("", 8)#hp[[1]][[1]]
class(a) <- "hclust"        # make it an hclust object

hc = as.dendrogram(a)

# Function to color branches
colbranches <- function(n, col)
{
  a <- attributes(n) # Find the attributes of current node
  # Color edges with requested color
  attr(n, "edgePar") <- c(a$edgePar, list(col=col, lwd=2))
  n # Don't forget to return the node!
}

plt_den = function(LVL, h){
  d1=color_branches(rev(hc), k=LVL, col = rainbow(8)[1+(3+sapply(hp[[LVL]], function(i) i[[1]]))%% 8])
  d1 = assign_values_to_branches_edgePar(d1, value = 7, edgePar = "lwd")
  
  plot(d1, lwd=2, lty = 3, axes = FALSE)
  rect(0, h, 10, 10, col='white', border=NA)
}
@

\begin{frame}[t]
\frametitle{Hierarchical mixture sequence}
\begin{itemize}
\item Repeatedly merge those components "more likely" to be considered as a single cluster

\begin{columns}
\begin{column}{0.90\textwidth}
\only<1>{
<<fig.width=8.5, fig.height=3>>=
lvl = 8
print(draw_partition(8))
@
}
\only<2>{
<<fig.width=8.5, fig.height=3>>=
lvl = 7
print(draw_partition(lvl))
@
}
\only<3>{
<<fig.width=8.5, fig.height=3>>=
lvl = 6
print(draw_partition(lvl))
@
}
\only<4>{
<<fig.width=8.5, fig.height=3>>=
lvl = 5
print(draw_partition(lvl))
@
}
\only<5>{
<<fig.width=8.5, fig.height=3>>=
lvl = 4
print(draw_partition(lvl))
@
}
\only<6>{
<<fig.width=8.5, fig.height=3>>=
lvl = 3
print(draw_partition(lvl))
@
}
\only<7>{
<<fig.width=8.5, fig.height=3>>=
lvl = 2
print(draw_partition(lvl))
@
}
\only<8->{
<<fig.width=8.5, fig.height=3>>=
lvl = 1
print(draw_partition(lvl))
@
}
\end{column}
\begin{column}{0.20\textwidth}
\only<1>{
<<fig.width=6, fig.height=6>>=
lvl = 8
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\only<2>{
<<fig.width=6, fig.height=6>>=
lvl = 7
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\only<3>{
<<fig.width=6, fig.height=6>>=
lvl = 6
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\only<4>{
<<fig.width=6, fig.height=6>>=
lvl = 5
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\only<5>{
<<fig.width=6, fig.height=6>>=
lvl = 4
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\only<6>{
<<fig.width=6, fig.height=6>>=
lvl = 3
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\only<7>{
<<fig.width=6, fig.height=6>>=
lvl = 2
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\only<8->{
<<fig.width=6, fig.height=6>>=
lvl = 1
par(mar=c(0,0,0,0))
plt_den(lvl, 8.5-lvl)
@
}
\end{column}
\end{columns}
\item<9> Strategies based on posterior probabilities
\[
\tau_{ij} = \frac{\pi_j f_j(x_i;\theta_j)}{\sum_{\ell=1}^K \pi_\ell f_\ell(x_i;\theta_\ell)}.
\]
\end{itemize}
\end{frame}

\section{Merging components based on posterior probability}

\begin{frame}[t]
\frametitle{Merging components based on posterior probability}

\begin{block}{Input}
A sample of probabilities to belong to each component $I_j$, 
\begin{columns}
\column{0.4\textwidth}
\[ \left[ \begin{array}{ccccc}
\idea{(}\tau_{11}\idea{,} & \dots & \tau_{1j}\idea{,} & \dots & \tau_{1k}\idea{),} \\
\vdots      & &    \vdots                     & &    \vdots                     \\
\idea{(}\tau_{i1}\idea{,} & \dots & \tau_{ij}\idea{,} & \dots & \tau_{ik}\idea{),} \\
\vdots      & &      \vdots                   & &       \vdots                  \\
\idea{(}\tau_{n1}\idea{,} & \dots & \tau_{nj}\idea{,} & \dots & \tau_{nk}\idea{)}
\end{array} \right] 
\idea{ \in \mathcal{S}^k } \]
\column{0.3\textwidth}
\end{columns}
\end{block}

\pause
\begin{alertblock}{Goal}
Merge components (sequentially) to obtain a hierarchy over the set of components % $\{C_1, \dots, C_k\}$. %In other words, obtain a binary tree with a set of leafs $\{C_1, \dots, C_k\}$
\end{alertblock}

\end{frame}

\begin{frame}[t]
\frametitle{The Shannon entropy approach}

\begin{alertblock}{The Shannon entropy approach (Baudry et al. (2010))}
Merge those component $I_a$ and $I_b$ in such a way that the resulting Shannon entropy is minimized.
\end{alertblock}

\begin{itemize}
\item The Shannon entropy of a posterior probability sample is 
\[
- \sum_{i=1}^n \sum_{j=1}^k \tau_{ij} log(\tau_{ij})
\]
\item To minimize the entropy after merging components $I_a$ and $I_b$, maximize
\[
\sum_{i=1}^n  (\tau_{i I_a}+\tau_{i I_b}) \log(\tau_{i I_a} + \tau_{i I_b}) - 
\sum_{i=1}^n \left\{ \tau_{i I_a} \log(\tau_{i I_a}) + \tau_{i I_b} \log(\tau_{i I_b})\right\}.
\]
\end{itemize}
\end{frame}

\begin{frame}[t]
\frametitle{The Shannon entropy approach}
\begin{itemize}
\item Consider a posterior probability vector $\left( \tau_{i1}, \tau_{i2}, \tau_{i3} \right)$.
\item For $\tau_3 = 0.2$\uncover<2->{, {\color{red}$\tau_3 = 0.4$}}\uncover<3->{, {\color{green}$\tau_3 = 0.6$}}\uncover<4->{ and {\color{blue}$\tau_3 = 0.8$}.}
\end{itemize}

\begin{columns}
\column{0.7\textwidth}
<<include=FALSE>>=
library(ggtern)
@
\only<1>{
<<fig.width=6.5, fig.height=5>>=
xlog = function(x) ifelse(x == 0, 0, x * log(x))
entr = function(x) -(xlog(x) + xlog(1-x))
p = ggplot()
for(i  in 1){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = xlog(1-other) - xlog(x) - xlog(1-other-x)), aes(x = x, y = ent_diff), col=i)
}
pentropy = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Shannon entropy') + coord_cartesian(xlim=c(0,1)) + theme(panel.grid=element_blank())

pscale = ggtern()
for(i  in 1){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(pentropy, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<2>{
<<fig.width=6.5, fig.height=5>>=
xlog = function(x) ifelse(x == 0, 0, x * log(x))
entr = function(x) -(xlog(x) + xlog(1-x))
p = ggplot()
for(i  in 1:2){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = xlog(1-other) - xlog(x) - xlog(1-other-x)), aes(x = x, y = ent_diff), col=i)
}
pentropy = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Shannon entropy') + coord_cartesian(xlim=c(0,1)) + theme(panel.grid=element_blank())

pscale = ggtern()
for(i  in 1:2){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(pentropy, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<3>{
<<fig.width=6.5, fig.height=5>>=
xlog = function(x) ifelse(x == 0, 0, x * log(x))
entr = function(x) -(xlog(x) + xlog(1-x))
p = ggplot()
for(i  in 1:3){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = xlog(1-other) - xlog(x) - xlog(1-other-x)), aes(x = x, y = ent_diff), col=i)
}
pentropy = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Shannon entropy') + coord_cartesian(xlim=c(0,1)) + theme(panel.grid=element_blank())

pscale = ggtern()
for(i  in 1:3){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(pentropy, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<4>{
<<fig.width=6.5, fig.height=5>>=
xlog = function(x) ifelse(x == 0, 0, x * log(x))
entr = function(x) -(xlog(x) + xlog(1-x))
p = ggplot()
for(i  in 1:4){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = xlog(1-other) - xlog(x) - xlog(1-other-x)), aes(x = x, y = ent_diff), col=i)
}
pentropy = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Shannon entropy') + coord_cartesian(xlim=c(0,1)) + theme(panel.grid=element_blank())

pscale = ggtern()
for(i  in 1:4){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(pentropy, vp = vprincipal)
print(pscale, vp=vscale)
@
}
<<include=FALSE>>=
detach("package:ggtern", unload=TRUE)
@
\end{columns}

\end{frame}

\begin{frame}[t]
\frametitle{The Aitchison norm as an entropy measure}

\begin{alertblock}{Approach using the Aitchison norm}
Merge those component $I_a$ and $I_b$ in such a way that
\[
\sum_{i=1}^n \|(\tau_{i I_a}, \tau_{i I_b})\|^2
\]
is minimum.
\end{alertblock}

\begin{itemize}
\item It measures the square distance to $\left(\frac{1}{2}, \frac{1}{2}\right)$ (minimum entropy).
\item In contrast to Shannon entropy, it only depends on components $I_a$ and $I_b$.
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{The Aitchison norm as an entropy measure}
\begin{itemize}
\item Given the posterior probability vector $\left( \tau_{i1}, \tau_{i2}, \tau_{i3} \right)$.
\item For $\tau_3 = 0.2$\uncover<2->{, {\color{red}$\tau_3 = 0.4$}}\uncover<3->{, {\color{green}$\tau_3 = 0.6$}}\uncover<4->{ and {\color{blue}$\tau_3 = 0.8$}.}
\end{itemize}

\begin{columns}
\column{0.7\textwidth}
<<include=FALSE>>=
library(ggtern)
@
\only<1>{
<<fig.width=6.5, fig.height=5>>=
p = ggplot()
for(i  in 1){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = -log((1-other-x)/x)^2), aes(x = x, y = ent_diff), col=i)
}
paitchison = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Minus the Aitchison norm') + coord_cartesian(xlim=c(0,1), ylim=c(-5, 1)) + theme(panel.grid=element_blank())
pscale = ggtern()
for(i  in 1){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(paitchison, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<2>{
<<fig.width=6.5, fig.height=5>>=
p = ggplot()
for(i  in 1:2){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = -log((1-other-x)/x)^2), aes(x = x, y = ent_diff), col=i)
}
paitchison = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Minus the Aitchison norm') + coord_cartesian(xlim=c(0,1), ylim=c(-5, 1)) + theme(panel.grid=element_blank())
pscale = ggtern()
for(i  in 1:2){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(paitchison, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<3>{
<<fig.width=6.5, fig.height=5>>=
p = ggplot()
for(i  in 1:3){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = -log((1-other-x)/x)^2), aes(x = x, y = ent_diff), col=i)
}
paitchison = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Minus the Aitchison norm') + coord_cartesian(xlim=c(0,1), ylim=c(-5, 1)) + theme(panel.grid=element_blank())
pscale = ggtern()
for(i  in 1:3){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(paitchison, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<4>{
<<fig.width=6.5, fig.height=5>>=
p = ggplot()
for(i  in 1:4){
  other = seq(0.2, 0.8, length.out=4)[i]
  p = p + geom_line(data = data.frame(x = seq(0, 1-other, 0.0001)) %>% mutate(ent_diff = -log((1-other-x)/x)^2), aes(x = x, y = ent_diff), col=i)
}
paitchison = p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('Minus the Aitchison norm') + coord_cartesian(xlim=c(0,1), ylim=c(-5, 1)) + theme(panel.grid=element_blank())
pscale = ggtern()
for(i  in 1:4){
  other = seq(0.2, 0.8, length.out=4)[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.85, y = 0.8)
print(paitchison, vp = vprincipal)
print(pscale, vp=vscale)
@
}
<<include=FALSE>>=
detach("package:ggtern", unload=TRUE)
@
\end{columns}

\end{frame}

\begin{frame}[t]
\frametitle{The missclassification approach}

\begin{alertblock}{The missclassification approach (Hennig (2010))}
Merge those component $I_a$ and $I_b$ for which the probability of assigning one observation generated by component $I_a$ to $I_b$ is maximum.
\end{alertblock}

\[
P(\{x_i \text{ assigned to } I_b\}|\{x_i \text{ generated by } I_a\}) =
\]
\[
\frac{{\color{blue}P( \{x_i \text{ assigned to } I_b\}, \{x_i \text{ generated by } I_a\})} }{ {\color{gg2}P(\{x_i \text{ generated by } I_a\})} }
\]
he proposed the estimator
\[
\frac{
{\color{blue}\frac{1}{n} \sum_{i=1}^n {\tau_{i I_a} \mathbbm{1}\left( \forall j\; \tau_{i I_{b}} \geq \tau_{i I_j} \right)}}
}{ 
{\color{gg2}\pi_{I_a}}
}.
\]
\pause
The estimator can be written as
\only<2>{%
\[
\frac{ \sum_{i=1}^n {\tau_{i I_a} \mathbbm{1}\left( \forall j\; \tau_{i I_{b}} \geq \tau_{i I_j} \right)}}{\sum_{i=1}^n \tau_{i I_a} }
\]
}
\only<3>{%
\[
\frac{ \sum_{i=1}^n {\tau_{i I_a} \red{\mathbbm{1}\left( \forall j\; \tau_{i I_{b}} \geq \tau_{i I_j} \right)}}}{\sum_{i=1}^n \tau_{i I_a} }
\]
}
\end{frame}

\begin{frame}[t]
\frametitle{The missclassification approach}

\begin{itemize}
\item Given the posterior probability vector $\left( \tau_{i1}, \tau_{i2}, \tau_{i3} \right)$.
\item Remember, the confusion is given by $\mathbbm{1}\left( \forall j\; \tau_{i I_{b}} \geq \tau_{i I_j} \right)$
\item For $\tau_3 = 0.1$\uncover<2->{, {\color{red}$\tau_3 = 0.3$}}\uncover<3->{ and {\color{green}$\tau_3 = 0.5$}.}
\end{itemize}

\begin{columns}
\column{0.7\textwidth}
<<include=FALSE>>=
library(ggtern)
@
\only<1>{
<<fig.width=6.5, fig.height=5>>=
d <- lapply(steps <- c(0.1, 0.3, 0.5), function(other) data.frame(x = seq(0, 1-other, 0.001)) %>% 
                                                            mutate(demp = ifelse(1-other-x < x & other < x, 1, 0),
                                                                   other = as.character(other))) %>% bind_rows %>% mutate(
                                                                     other = factor(other, labels = sprintf("tau[3]==%3.1f",steps)))
p = ggplot()
for(i  in 1){
  p = p + geom_point(data = d %>% subset(other==sprintf("tau[3]==%3.1f",steps[i])), aes(x = x, y = demp), col=i, shape=15, size=1)
}
pdemp<-p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('DEMP criteria') + coord_cartesian(xlim=c(0,1))  + 
  theme(panel.grid=element_blank(),
        strip.text.y = element_text(size=12, face="bold"),
        strip.background = element_rect(colour="black", fill="white"))+ylim(0,1)

pscale = ggtern()
for(i  in 1){
  other = steps[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.8, y = 0.5)
print(pdemp, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<2>{
<<fig.width=6.5, fig.height=5>>=
d <- lapply(steps <- c(0.1, 0.3, 0.5), function(other) data.frame(x = seq(0, 1-other, 0.001)) %>% 
                                                            mutate(demp = ifelse(1-other-x < x & other < x, 1, 0),
                                                                   other = as.character(other))) %>% bind_rows %>% mutate(
                                                                     other = factor(other, labels = sprintf("tau[3]==%3.1f",steps)))
p = ggplot()
for(i  in 2){
  p = p + geom_point(data = d %>% subset(other==sprintf("tau[3]==%3.1f",steps[i])), aes(x = x, y = demp), col=i, shape=15, size=1)
}
pdemp<-p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('DEMP criteria') + coord_cartesian(xlim=c(0,1))  + 
  theme(panel.grid=element_blank(),
        strip.text.y = element_text(size=12, face="bold"),
        strip.background = element_rect(colour="black", fill="white"))+ylim(0,1)

pscale = ggtern()
for(i  in 2){
  other = steps[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.8, y = 0.5)
print(pdemp, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<3>{
<<fig.width=6.5, fig.height=5>>=
d <- lapply(steps <- c(0.1, 0.3, 0.5), function(other) data.frame(x = seq(0, 1-other, 0.001)) %>% 
                                                            mutate(demp = ifelse(1-other-x < x & other < x, 1, 0),
                                                                   other = as.character(other))) %>% bind_rows %>% mutate(
                                                                     other = factor(other, labels = sprintf("tau[3]==%3.1f",steps)))
p = ggplot()
for(i  in 3){
  p = p + geom_point(data = d %>% subset(other==sprintf("tau[3]==%3.1f",steps[i])), aes(x = x, y = demp), col=i, shape=15, size=1)
}
pdemp<-p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('DEMP criteria') + coord_cartesian(xlim=c(0,1))  + 
  theme(panel.grid=element_blank(),
        strip.text.y = element_text(size=12, face="bold"),
        strip.background = element_rect(colour="black", fill="white"))+ylim(0,1)

pscale = ggtern()
for(i  in 3){
  other = steps[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.8, y = 0.5)
print(pdemp, vp = vprincipal)
print(pscale, vp=vscale)
@
}
<<include=FALSE>>=
detach("package:ggtern", unload=TRUE)
@
\end{columns}

\end{frame}

\begin{frame}
\frametitle{The log-ratio as a misclassification measure}

\begin{alertblock}{Approach using the logratio}
Merge those component $I_a$ and $I_b$ in such a way that
\[
\frac{ \sum_{i=1}^n {\tau_{i I_a} log(\tau_{i I_b}/\tau_{i I_a}) }}{\sum_{i=1}^n \tau_{i I_a} }
\]
is minimum.
\end{alertblock}

\begin{itemize}
\item We've replaced the confusion measure $\mathbbm{1}\left( \forall j\; \tau_{i I_{b}} \geq \tau_{i I_j} \right)$ by $log(\tau_{i I_b}/\tau_{i I_a})$.
\item It measures how relatively big is $\tau_{i I_b}$ to $\tau_{i I_b}$.
\item A similar measure has been proposed by Longford~\&~Bartosova~(2014) ($\frac{\tau_{i I_b}}{\tau_{i I_a} + \tau_{iI_b}}$).
\item In contrast to DEMP, it only depends on $I_a$ and $I_b$.
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{The log-ratio as a misclassification measure}
\begin{itemize}
\item Given the posterior probability vector $\left( \tau_{i1}, \tau_{i2}, \tau_{i3} \right)$.
\item Remember, the confusion now is given by $log\left(\tau_{i I_{b}}/\tau_{i I_{a}} \right)$
\item For $\tau_3 = 0.1$\uncover<2->{, {\color{red}$\tau_3 = 0.3$}}\uncover<3->{ and {\color{green}$\tau_3 = 0.5$}.}
\end{itemize}
\begin{columns}
\column{0.7\textwidth}
<<include=FALSE>>=
library(ggtern)
@
\only<1>{
<<fig.width=6.5, fig.height=5>>=
d <- lapply(steps <- c(0.1, 0.3, 0.5), function(other) data.frame(x = seq(0, 1-other, 0.001)) %>% 
                                                            mutate(log = log(x/(1-other-x)),
                                                                   other = as.character(other))) %>% bind_rows %>% mutate(
                                                                     other = factor(other, labels = sprintf("tau[3]==%3.1f",steps)))
p = ggplot()
for(i  in 1){
  p = p + geom_line(data = d %>% subset(other==sprintf("tau[3]==%3.1f",steps[i])), aes(x = x, y = log), col=i, shape=15, size=1)
}
pdemp<-p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('DEMP criteria') + coord_cartesian(xlim=c(0,1))  + 
  theme(panel.grid=element_blank(),
        strip.text.y = element_text(size=12, face="bold"),
        strip.background = element_rect(colour="black", fill="white"))

pscale = ggtern()
for(i  in 1){
  other = steps[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.8, y = 0.35)
print(pdemp, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<2>{
<<fig.width=6.5, fig.height=5>>=
d <- lapply(steps <- c(0.1, 0.3, 0.5), function(other) data.frame(x = seq(0, 1-other, 0.001)) %>% 
                                                            mutate(log = log(x/(1-other-x)),
                                                                   other = as.character(other))) %>% bind_rows %>% mutate(
                                                                     other = factor(other, labels = sprintf("tau[3]==%3.1f",steps)))
p = ggplot()
for(i  in 1:2){
  p = p + geom_line(data = d %>% subset(other==sprintf("tau[3]==%3.1f",steps[i])), aes(x = x, y = log), col=i, shape=15, size=1)
}
pdemp<-p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('DEMP criteria') + coord_cartesian(xlim=c(0,1))  + 
  theme(panel.grid=element_blank(),
        strip.text.y = element_text(size=12, face="bold"),
        strip.background = element_rect(colour="black", fill="white"))

pscale = ggtern()
for(i  in 1:2){
  other = steps[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.8, y = 0.35)
print(pdemp, vp = vprincipal)
print(pscale, vp=vscale)
@
}
\only<3>{
<<fig.width=6.5, fig.height=5>>=
d <- lapply(steps <- c(0.1, 0.3, 0.5), function(other) data.frame(x = seq(0, 1-other, 0.001)) %>% 
                                                            mutate(log = log(x/(1-other-x)),
                                                                   other = as.character(other))) %>% bind_rows %>% mutate(
                                                                     other = factor(other, labels = sprintf("tau[3]==%3.1f",steps)))
p = ggplot()
for(i  in 1:3){
  p = p + geom_line(data = d %>% subset(other==sprintf("tau[3]==%3.1f",steps[i])), aes(x = x, y = log), col=i, shape=15, size=1)
}
pdemp<-p + theme_classic() + 
  xlab(expression(tau[2])) + ylab('DEMP criteria') + coord_cartesian(xlim=c(0,1))  + 
  theme(panel.grid=element_blank(),
        strip.text.y = element_text(size=12, face="bold"),
        strip.background = element_rect(colour="black", fill="white"))

pscale = ggtern()
for(i  in 1:3){
  other = steps[i]
  pscale = pscale + geom_Tline(Tintercept=other, col=i)
}
pscale = pscale +
  Tlab(expression(tau[3])) + Llab(expression(tau[1])) + Rlab(expression(tau[2])) + 
  theme_classic() + theme(panel.grid.tern=element_blank(), 
                     axis.tern.ticks=element_blank(), 
                     axis.tern.text.T=element_blank(),
                     axis.tern.text.R=element_blank(),
                     axis.tern.text.L=element_blank(),
                     axis.tern.showarrows = F)

plot.new()
vprincipal <- viewport(width = 1, height = 1, x = 0.5, y = 0.5)
vscale <- viewport(width = 0.32, height = 0.4, x = 0.8, y = 0.35)
print(pdemp, vp = vprincipal)
print(pscale, vp=vscale)
@
}
<<include=FALSE>>=
detach("package:ggtern", unload=TRUE)
@
\end{columns}

\end{frame}


\section{Advantages of using a compositional approach}

\begin{frame}
\frametitle{Scale invariance}

\begin{columns}
\column{0.4\textwidth}
\[ \left[ \begin{array}{ccccc}
\idea{(}\tau_{11}\idea{,} & \dots & \tau_{1j}\idea{,} & \dots & \tau_{1k}\idea{),} \\
\vdots      & &    \vdots                     & &    \vdots                     \\
\idea{(}\tau_{i1}\idea{,} & \dots & \tau_{ij}\idea{,} & \dots & \tau_{ik}\idea{),} \\
\vdots      & &      \vdots                   & &       \vdots                  \\
\idea{(}\tau_{n1}\idea{,} & \dots & \tau_{nj}\idea{,} & \dots & \tau_{nk}\idea{)}
\end{array} \right] 
\idea{ \in \mathcal{S}^k } \]
\column{0.3\textwidth}
\end{columns}

\begin{itemize}
\item Probabilities are not restricted to be probabilities, they can be positive measurements containing relative information between components. 
\item Probabilities $\rightarrow$ Weights. Fuzzy clustering.
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Subcompositional coherence}

IF we knew that some subcompositions were going to be forming a single cluster, then we could find a hierchical merging sequence inside each subcomposition in parallel without considering the other subcompositions.

\begin{columns}
\column{0.95\textwidth}
<<fig.width=8.5, fig.height=3>>=
source("http://addictedtor.free.fr/packages/A2R/lastVersion/R/code.R")

set.seed(50)
#rnorm(1000, mean=1, sd=100)
x = lapply(1:20, function(m) rnorm(100, mean = m, sd = 200)) %>% unlist
hc = hclust(log(stats::dist(x, method="euclidean")), method="ward.D")

A2Rplot(hc, k = 8, boxes = FALSE, col.up = "gray50", main = '', show.labels = F)
@
\end{columns}

\end{frame}

\section{Final comments}
\begin{frame}
\frametitle{Conclusions and open questions}
\begin{itemize}
\item The introduced approaches are independent from other components.
\item CoDa approach allow us to merge mixture components using a well established principles
\end{itemize}

\begin{itemize}
\item The merging approach is the amalgamation (one observation can only be considered from one component). Can we use other forms of merging? Maybe geometrical mean between components? What does this form of merging mean?
\item The merging approach is similar to the approach of principal components. Does it make sense to consider principal component here?
\end{itemize}
\end{frame}

\end{document}