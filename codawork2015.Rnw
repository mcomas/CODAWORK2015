\documentclass[10pt]{beamer}

\usepackage{color}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{array}
\usepackage{amsmath, amssymb, bbm}
\usepackage{verbatim}
\usepackage{relsize}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{ragged2e}
\usetheme{Warsaw}
\usepackage{dsfont}
%\usecolortheme{lily}

\definecolor{obs}{RGB}{53,106,160}
\definecolor{post}{RGB}{0,110,46}
\definecolor{class}{RGB}{160,110,46}
\definecolor{idea}{RGB}{162,162,162}

\definecolor{gg1}{RGB}{248,118,109}
\definecolor{gg2}{RGB}{183,159,0}
\definecolor{gg3}{RGB}{0,186,56}
\definecolor{gg4}{RGB}{0,191,196}
\definecolor{gg5}{RGB}{97,156,255}
\definecolor{gg6}{RGB}{245,100,227}

\newcommand{\obs}[1]{{\color{obs}#1}}
\newcommand{\post}[1]{{\color{post}#1}}
\newcommand{\class}[1]{{\color{class}#1}}
\newcommand{\idea}[1]{{\uncover<2>{\color{idea}#1}}}
\newcommand{\tidea}[2]{{\uncover<#1>{\color{idea}#2}}}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\blue}[1]{{\color{blue}#1}}

\newcommand{\gga}[1]{{\color{gg1}#1}}
\newcommand{\ggb}[1]{{\color{gg2}#1}}
\newcommand{\ggc}[1]{{\color{gg3}#1}}
\newcommand{\ggd}[1]{{\color{gg4}#1}}
\newcommand{\gge}[1]{{\color{gg5}#1}}
\newcommand{\ggf}[1]{{\color{gg6}#1}}

\title{Four slides}
\author{Marc Comas-Cuf\'{\i}}
\date{28th January 2015}

\begin{document}
\SweaveOpts{concordance=TRUE}

\begin{frame}
\titlepage
\end{frame}

<<echo=FALSE, include=FALSE>>=
set.seed(1)
library(ggplot2)
rnormmix = function(n, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1)){
  df = apply(cbind(mean, sd), 1, function(pars) rnorm(n, mean=pars[1], sd=pars[2]))
  z = sapply(sample(1:3, size = n, replace = TRUE, prob = pi), function(i) 1:3 == i)
  df[t(z)]
}
dnormmix = function(x, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1)){
  df = apply(cbind(pi, mean, sd), 1, function(pars) pars[1] * dnorm(x, mean=pars[2], sd=pars[3]))
  apply(df, 1, sum)
}
cnormmix = function(x, pi= c(1/3, 1/3, 1/3), 
                    mean = c(-2, 0, 2),
                    sd = c(1, 1, 1),
                    class = 1:length(pi)){
  df = apply(cbind(pi, mean, sd), 1, function(pars) pars[1] * dnorm(x, mean=pars[2], sd=pars[3]))
  as.factor(class[apply(df, 1, which.max)])
}
@


%%%%%%%%%%%%
%%% FRAME 1

<<echo=FALSE>>= 
set.seed(2)
Pi = c(2/9, 4/9, 3/9)
Mean = c(-2, 3.5, 5)
Sd = c(0.65,1.2,0.8)
v_xlim = c(-5, 8)
df = data.frame('x' = rnormmix(n = 100,  pi = Pi, mean = Mean, sd = Sd))
df$f = dnormmix(df$x, pi = Pi, mean = Mean, sd = Sd)
df.dens = data.frame('x' = seq(-5, 10, 0.2))
df.dens$f = dnormmix(df.dens$x, pi = Pi, mean = Mean, sd = Sd)
df.dens$f1 = Pi[1] * dnorm(df.dens$x, mean = Mean[1], sd = Sd[1])
df.dens$f2 = Pi[2] * dnorm(df.dens$x, mean = Mean[2], sd = Sd[2])
df.dens$f3 = Pi[3] * dnorm(df.dens$x, mean = Mean[3], sd = Sd[3])
df$class = cnormmix(df$x, pi = Pi, mean = Mean, sd = Sd)
df$class2 = cnormmix(df$x, pi = Pi, mean = Mean, sd = Sd, class=c(1,2,2))
p1 <- ggplot() + 
  geom_histogram(data=df, aes(x=x, y = ..density..), binwidth=0.5, col='black', fill='white') +
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.01), alpha=0.8) +
  theme_bw() + xlim(v_xlim) + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) +
  ylab(NULL)


p2 <- p1 + geom_line(data=df.dens, aes(x=x, y=f), size = 1)
  
p3 <- p1 +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2), size = 1, col = 'green', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f3), size = 1, col = 'blue', alpha=0.6) +
  geom_line(data=df.dens, aes(x=x, y=f), size = 1)

p1c <- ggplot() + 
  geom_histogram(data=df, aes(x=x, y = ..density..), binwidth=0.5, col='black', fill='white', alpha=0.6) +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2), size = 1, col = 'green', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f3), size = 1, col = 'blue', alpha=0.6) + 
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.01, col=class), alpha=0.2) + 
  theme_bw() +  theme(legend.position="none") +xlim(v_xlim) + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) + ylab(NULL) +  scale_color_manual(values = c("red", "green", "blue"))

p4 <- p1 +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2+f3), size = 1, col = 'green', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f), size = 1)

p1d <- ggplot() + 
  geom_histogram(data=df, aes(x=x, y = ..density..), binwidth=0.5, col='black', fill='white', alpha=0.6) +
  geom_line(data=df.dens, aes(x=x, y=f1), size = 1, col = 'red', alpha=0.6) + 
  geom_line(data=df.dens, aes(x=x, y=f2+f3), size = 1, col = 'green', alpha=0.6) +
  geom_segment(data=df, aes(x=x, xend=x, y=0, yend=0.01, col=class2), alpha=0.2) + 
  theme_bw() +  theme(legend.position="none") +xlim(v_xlim) + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) + ylab(NULL) +  scale_color_manual(values = c("red", "green", "blue"))
@

\begin{frame}[fragile]
\frametitle{Stating the problem}

How many clusters do see?

<<echo=FALSE, fig=TRUE, width=6, height=4>>= 
print(p1) 
@

\end{frame}


\begin{frame}[fragile]
\frametitle{Stating the problem}

How many clusters do see?

\uncover<2->{
\only<1-2>{%
$$f(x) = {\color{black}\pi_1 f_1(x;\theta_1)} + {\color{black}\pi_2 f_2(x;\theta_2)} + {\color{black}\pi_3 f_3(x;\theta_3)}$$
}%
\only<3>{%
$$f(x) = {\color{black}\hat{\pi}_1 f_1(x;\hat{\theta}_1)} + {\color{black}\hat{\pi}_2 f_2(x;\hat{\theta}_2)} + {\color{black}\hat{\pi}_3 f_3(x;\hat{\theta}_3)}$$
}%
\only<4-5>{%
$$f(x) = {\color{red}\hat{\pi}_1 f_1(x;\hat{\theta}_1)} + {\color{green}\hat{\pi}_2 f_2(x;\hat{\theta}_2)} + {\color{blue}\hat{\pi}_3 f_3(x;\hat{\theta}_3)}$$
}
\only<6->{%
$$f(x) = {\color{red}\hat{\pi}_1 f_1(x;\hat{\theta}_1)} + {\color{green}\hat{\pi}_2 f_2(x;\hat{\theta}_2)} + {\color{green}\hat{\pi}_3 f_3(x;\hat{\theta}_3)}$$
}
}
\begin{center}
\setkeys{Gin}{width=0.5\linewidth}
\only<1-2>{%
<<echo=FALSE, fig=TRUE, width=6, height=4>>= 
print(p1) 
@
}%
\only<3>{%
<<echo=FALSE, fig=TRUE, width=6, height=4>>= 
print(p2) 
@
}%
\only<4>{%
<<echo=FALSE, fig=TRUE, width=6, height=4>>= 
print(p3) 
@
}%
\only<5>{%
<<echo=FALSE, fig=TRUE, width=6, height=4>>= 
print(p1c) 
@
}%
\only<6>{%
<<echo=FALSE, fig=TRUE, width=6, height=4>>= 
print(p4) 
@
}%
\only<7>{%
<<echo=FALSE, fig=TRUE, width=6, height=4>>= 
print(p1d) 
@
}%

\uncover<2->{
The best model has \alert{three} components.\\
\uncover<5->{
\only<1-5>{\begin{itemize}\item Separating with \alert{three} clusters doesn't make sense.\end{itemize}}
\only<6->{\begin{itemize}\item Separating with \alert{two} clusters makes sense.\end{itemize}}
}
}
\end{center}
\end{frame}

% \begin{frame}[fragile,t]
% \frametitle{What we do}
% 
% \uncover<2->{
% We estimate a finite mixture
% \[ f(x) = {\color{blue}\pi_1 f_1(x)} + {\color{blue}\pi_2 f_2(x)} + {\color{blue}\pi_3 f_3(x)} + {\color{blue}\pi_4 f_4(x)} + {\color{blue}\pi_5 f_5(x)} + {\color{blue}\pi_6 f_6(x)} \]}
% 
% \begin{center}
% \only<1>{\includegraphics[width=0.4\textwidth]{baudry_ex4_1.pdf}}%
% \only<2->{\includegraphics[width=0.4\textwidth]{baudry_ex4_1_contour6.pdf}}
% \end{center}
% %\only<2>{\[ f(x) = \gga{\pi_1 f_1(x)} + \ggb{\pi_2 f_2(x)} + \ggc{\pi_3 f_3(x)} + \ggd{\pi_4 f_4(x)} + \gge{\pi_5 f_5(x)} + \ggf{\pi_6 f_6(x)} \]}
% 
% \uncover<3->{
%   \only<1-3>{%
%   \begin{center}
%   \includegraphics[width=0.8\textwidth]{baudry_ex4_1_all_distributions_one_clean.pdf}%
%   \end{center}}
%   \only<4>{%
%   \begin{center}
%   \includegraphics[width=0.8\textwidth]{baudry_ex4_1_all_distributions_one.pdf}%
%   \end{center}}
%   \only<5>{%
%   \begin{center}
%   \includegraphics[width=0.8\textwidth]{baudry_ex4_1_all_distributions_one_tau.pdf}%
%   \end{center}}
% }
% \end{frame}
% 
% \begin{frame}[fragile]
% \frametitle{What we got}
% \begin{itemize}
% \item $\left(0.99, 5.1e{-20}, 1.6e{-38},8.3e{-66},9.5e{-66},0.0079\right)$ is an element of a restricted space called Simplex, $\mathcal{S}_d$,
% \[
% \mathcal{S}_d = \left\{ (x_1, \dots, x_d) \;|\; x_i > 0 \text{ for } i = 1,\dots, d  \text{ and } \sum_{i=1}^n x_i = 1 \right\},
% \]
% i.e. an space where the components of their elements are positive and sum up to one.
% \pause
% \item There is a methodology to deal with this kind of data.
% \begin{itemize}
% \item $\mathcal{S}_d$ is a geometric space with its own structure and operations (perturbation $\oplus$, powering $\odot$).
% \item The origin of $\mathcal{S}_d$ space is the composition $(\frac{1}{d}, \dots, \frac{1}{d})$.
% \end{itemize}
% \end{itemize}
% 
% \pause
% 
% \begin{alertblock}{What we got}
% \emph{Higher} the confusion is between components, \\ \emph{closer} are the posterior probabilities to the origin.
% \end{alertblock}
% 
% \end{frame}
% 
% \begin{frame}[fragile]
% \frametitle{How what we got contribute to solve the problem}
% \begin{itemize}
% \item Components can be merged using the information contained on the posterior probabilities
% \pause
% \item The approach does not depend on the distribution. It works with gaussian, multinomial, etc
% \pause
% \item The approach can be easily adapt to different scenarios 
% \begin{description}
% \item [Fuzzy clustering] Instead of posterior probabilities, fuzzy clustering uses the membership weights
% \item [Expert systems] Instead of posterior probabilities, an expert system uses a value given by an expert
% \end{description}
% \end{itemize}
% 
% \end{frame}

\end{document}